{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Project 1</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will get the content for the artists in letter G\n",
    "#imports Beautiful Soup in order to make requests to the url and access page contents\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import random\n",
    "\n",
    "url=\"https://www.azlyrics.com/g.html\"\n",
    "page=requests.get(url)\n",
    "soup=BeautifulSoup(page.content,\"lxml\")\n",
    "\n",
    "#finds all artist links from the link and stores them in variable x\n",
    "x=soup.find_all(class_=\"col-sm-6 text-center artist-col\")\n",
    "links=[]\n",
    "artist_names=[]\n",
    "\n",
    "#loops to find all a-tags from x and gets each artist link and the artist name and appends them to a list\n",
    "for col in x:\n",
    "    a_tags=col.find_all(\"a\")\n",
    "    for item in a_tags:\n",
    "        links.append(item.get('href'))\n",
    "        artist_names.append(item.text)\n",
    "\n",
    "# gets additional artist links\n",
    "artist_urls=[\"https://www.azlyrics.com/\"+addition for addition in links]\n",
    "\n",
    "all_urls=[] \n",
    "all_albums=[] \n",
    "all_songTitles=[]\n",
    "all_names=[]\n",
    "\n",
    "\n",
    "# z zips artist names and artist urls into list form\n",
    "z=list(zip(artist_names,artist_urls))\n",
    "\n",
    "\n",
    "\n",
    "# iterates through artist names and artist urls\n",
    "for item in z:\n",
    "    this_name=item[0]\n",
    "    url=item[1]\n",
    "    page=requests.get(url)\n",
    "    soup=BeautifulSoup(page.content, \"lxml\")\n",
    "    divs=soup.find_all(\"div\")\n",
    "    print(this_name, page.status_code)\n",
    "    current_album=\"\" #empty current_album\n",
    "    #For loop checks for div tags with an attirbute of class\n",
    "    for div in divs:\n",
    "        if div.has_attr(\"class\"):\n",
    "            # checks if class has a album and updates current album with its actual text\n",
    "            if div.attrs[\"class\"][0]==\"album\":\n",
    "                current_album=div.text\n",
    "            # else it checks if its a song then append to the following lists    \n",
    "            elif div.attrs[\"class\"][0] == \"listalbum-item\":\n",
    "                all_urls.append(div.a.get(\"href\"))\n",
    "                all_albums.append(current_album)\n",
    "                all_songTitles.append(div.text)\n",
    "                all_names.append(this_name)\n",
    "    # pauses each request to help from getting blocked from website\n",
    "    time.sleep(random.randrange(5,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separates the year from the album for all album list\n",
    "#Check if the last character is \")\" and second to last indice is numerical\n",
    "indice=[i for i,s in enumerate(all_albums) if s.endswith(\")\") and s[-2].isdigit]\n",
    "#gives the album name and the year \n",
    "gd_albums=[all_albums[i] for i in indice] \n",
    "#Gets the year\n",
    "years=[s[-5:-1] for s in gd_albums] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#writes onto CSV file\n",
    "\n",
    "# D is a list of the following and lists the CSV file order\n",
    "D=list(zip(all_names, all_songTitles, years, all_urls))\n",
    "\n",
    "import csv\n",
    "\n",
    "# writes the CSV file using D and names the columns\n",
    "with open('igonzal_project1_allSongs_urls.csv','w', encoding=\"utf-8\", newline='') as myfile:\n",
    "    wr = csv.writer(myfile)\n",
    "    wr.writerow((\"artist name\",\"song title\",\"year\", \"lyrics url\"))\n",
    "    wr.writerows(D)\n",
    "myfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Part 4-5</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#categorize the songs before 1970 and after 1970\n",
    "\n",
    "new_urls=[]\n",
    "new_albums=[]\n",
    "new_songTitles=[]\n",
    "new_names=[]\n",
    "new_years=[]\n",
    "old_urls=[]\n",
    "old_albums=[]\n",
    "old_songTitles=[]\n",
    "old_names=[]\n",
    "old_years=[]\n",
    "\n",
    "counter=0\n",
    "\n",
    "# iterates through all albums\n",
    "for album in all_albums:\n",
    "    #Check if the last character is a \")\" and second to last indice is numerical\n",
    "    if album.endswith(\")\") and album[-2].isdigit():\n",
    "        #convert strings to intigers and ignore characters\n",
    "        year=album[-5:-1]\n",
    "        year=int(''.join(c for c in year if c.isdigit()))\n",
    "        #year=int(album[-5:-1])#code from lecture\n",
    "        # checks if the year is greater than 1970 and append the newer contents to their identified lists\n",
    "        if int(year)>1970:\n",
    "            new_urls.append(all_urls[counter])\n",
    "            new_albums.append(all_albums[counter])\n",
    "            new_songTitles.append(all_songTitles[counter])\n",
    "            new_names.append(all_names[counter])\n",
    "            new_years.append(year)\n",
    "        # appends the remaining contents to their respective list\n",
    "        else:\n",
    "            old_urls.append(all_urls[counter])\n",
    "            old_albums.append(all_albums[counter])\n",
    "            old_songTitles.append(all_songTitles[counter])\n",
    "            old_names.append(all_names[counter])\n",
    "            old_years.append(year)\n",
    "    counter+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates a random sample of songs after 1970  \n",
    "\n",
    "\n",
    "import random\n",
    "\n",
    "#list of zipped new and old contents\n",
    "#takes a 10 percent sample of D and sets it to new samp\n",
    "#takes a random sample of new samp and D \n",
    "D=list(zip(new_names,new_songTitles,new_years,new_urls))\n",
    "old_contents=list(zip(old_names,old_songTitles,old_years,old_urls))\n",
    "new_samp = 10 * int(len(D)) // 100\n",
    "new_contents = random.sample(D, new_samp)\n",
    "\n",
    "\n",
    "import csv\n",
    "# writes the 10% sample csv with both the old contents and the new contents sample\n",
    "with open('igonzal_project1_sampledSongs_urls.csv','w', encoding=\"utf-8\", newline='') as myfile:\n",
    "    wr = csv.writer(myfile)\n",
    "    wr.writerow((\"artist name\",\"song title\",\"year\", \"lyrics url\"))\n",
    "    wr.writerows(old_contents)\n",
    "    wr.writerows(new_contents)\n",
    "myfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Part 6-8</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes away the first three characters from new_urls\n",
    "last_part_new_url = [x[3:] for x in new_urls]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#takes both parts of the url and combines them into a single link\n",
    "complete_new_url = [\"https://www.azlyrics.com/\"+addition for addition in last_part_new_url]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_lyrics_list = []\n",
    "# loops through each full url and parses through the page contents\n",
    "# finds each lyric location and appends them to the list\n",
    "for x in complete_new_url:\n",
    "    page=requests.get(x)\n",
    "    page.status_code\n",
    "    soup=BeautifulSoup(page.content, \"html.parser\")\n",
    "    print(soup.prettify())\n",
    "    tag_for_lyrics=soup.find_all(class_=\"col-xs-12 col-lg-8 text-center\")\n",
    "    tag_for_lyrics[0].text\n",
    "    results = tag_for_lyrics[0].text.split(\"\\n\")\n",
    "    new_lyrics_list.append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes away the first three characters from new_urls\n",
    "clean_old_url=[x[3:] for x in old_urls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_old_url = [\"https://www.azlyrics.com/\"+addition for addition in clean_old_url]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_lyrics_list=[]\n",
    "# loops through each full url and parses through the page contents\n",
    "# finds each lyric location and appends them to the list\n",
    "for x in complete_old_url:\n",
    "    page=requests.get(x)\n",
    "    page.status_code\n",
    "    soup=BeautifulSoup(page.content, \"html.parser\")\n",
    "    print(soup.prettify())\n",
    "    tag_for_lyrics=soup.find_all(class_=\"col-xs-12 col-lg-8 text-center\")\n",
    "    tag_for_lyrics[0].text\n",
    "    results = tag_for_lyrics[0].text.split(\"\\n\")\n",
    "    old_lyrics_list.append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completed_new_lyrics=list(zip(new_names, new_songTitles, new_years, new_urls, new_lyrics_list))\n",
    "completed_old_lyrics=list(zip(old_names, old_songTitles, old_years, old_urls, old_lyrics_list))\n",
    "\n",
    "# creates a zip list for both old lyrics and new lyrics\n",
    "# Wries a new csv file with the old and new lyrics and new columns\n",
    "\n",
    "import csv\n",
    "\n",
    "with open('igonzal_project1_lyrics.csv','w', encoding=\"utf-8\", newline='') as myfile:\n",
    "    wr = csv.writer(myfile)\n",
    "    wr.writerow((\"artist name\",\"song title\",\"year\", \"lyrics url\", \"lyrics text\"))\n",
    "    wr.writerows(completed_old_lyrics)\n",
    "    wr.writerows(completed_new_lyrics)\n",
    "myfile.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
